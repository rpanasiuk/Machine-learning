{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning - using LASSO to select features.\n",
    "\n",
    " This is one of my training projects. The main task is to investigate tuning parameter impact on RSS and magnitude of coefficients using wide range of lambda values. Task idea and dataset come from coursera's machine learning course (one of the quiz sections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "from pythonds.basic.stack import Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Loading the sales dataset using pandas. Setting up column data types at the beginning may avoid memory problems with huge datasets (dtype determination of each column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms': float, 'waterfront': int, 'sqft_above': int, 'sqft_living15': float, 'grade': int,\n",
    "              'yr_renovated': int, 'price': float, 'bedrooms': float, 'zipcode': str, 'long': float, \n",
    "              'sqft_lot15': float, 'sqft_living': float, 'floors': float, 'condition': int, 'lat': float, 'date': str,\n",
    "              'sqft_basement': int, 'yr_built': int, 'id': str, 'sqft_lot': int, 'view': int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformating existing inputs to get new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(np.sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(np.sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "                'bathrooms',\n",
    "                'sqft_living', 'sqft_living_sqrt',\n",
    "                'sqft_lot', 'sqft_lot_sqrt',\n",
    "                'floors', 'floors_square',\n",
    "                'waterfront', 'view', 'condition', 'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', 'yr_renovated'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning regression weights using large L1 penalty value - 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True)\n",
    "model_all.fit(sales[all_features], sales['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso approach brings sparse solutions. Most of the weights were excluded from the model when we put large L1 penalty value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 17\n",
      "[   134.43931396  24750.00458561  61749.10309071]\n"
     ]
    }
   ],
   "source": [
    "print('Number of inputs: {}'.format(len(all_features)))\n",
    "print(model_all.coef_[model_all.coef_ != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing splitted data sets\n",
    "\n",
    "Getting already splitted up data into testing, training, validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('wk3_kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(np.sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(np.sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(np.sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(np.sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(np.sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(np.sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting L1 penalty\n",
    "\n",
    "Creating an array with L1 penalty values for further impact exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty = np.logspace(1, 7, num=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to use prepared training and validation sets to learn new models with 13 different L1 penalties. Loop puts key-value pairs of L1 penalty and equivalent RSS value for this specific parameter to 'rss_dict'. The goal is to define penalty value where we get the lowest RSS in total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_dict = {}\n",
    "for l1 in l1_penalty:\n",
    "    model = linear_model.Lasso(alpha=l1, normalize=True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    prediction = model.predict(validation[all_features])\n",
    "    rss = sum((prediction - validation['price']) ** 2)\n",
    "    rss_dict[l1] = rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_optimum = list(rss_dict.keys())[list(rss_dict.values()).index(min(rss_dict.values()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 penalty value that produced the lowest RSS error was 10 (the lowest one from penalties set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the RSS on test data with the best L1 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = linear_model.Lasso(alpha=l1_optimum, normalize=True)\n",
    "model_test.fit(training[all_features], training['price'])\n",
    "prediction = model_test.predict(testing[all_features])\n",
    "rss_test = sum((prediction - testing['price']) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of nonzero weights for the best L1 penalty including intercept weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_weights = np.count_nonzero(model_test.coef_) + np.count_nonzero(model_test.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring some range of L1 penalty values to get desired sparsity\n",
    "\n",
    "Task - limit a model to 7 nonzero weights of features and find a narrow region of L1 penalty values where models are likely to have desired number of weights. Find both ends of narrow range of L1 penalty.\n",
    "\n",
    "It can be done with L1 penalty values generator working in certain range. When penalty value hits number of nonzero weights of the model equal to 7, min_l1 variable is being changed to actual penalty value. When model with some penalty value hits number of nonzero weights larger than desired we get previous penalty value using Stack() methods. The while loop contains 2 more scenarios where there is no such desired L1 penalty or we found only one end of narrow region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_generator(start, stop, step=1):\n",
    "    return (x for x in range(start, stop+1, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_val = 100\n",
    "stopping_val = 300\n",
    "step_val = 1\n",
    "\n",
    "gen = l1_generator(starting_val, stopping_val, step_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = Stack()\n",
    "\n",
    "min_l1 = None\n",
    "max_l2 = None\n",
    "\n",
    "max_non_zeros = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    model_gen = linear_model.Lasso(alpha=next(gen), normalize=True)\n",
    "    model_gen.fit(training[all_features], training['price'])\n",
    "    # Checking if # of nonzero coefficients is equal to max_non_zeros value.    \n",
    "    x = (np.count_nonzero(model_gen.coef_) == max_non_zeros)\n",
    "    \n",
    "    # Getting the head of our range.\n",
    "    if x and min_l1 is None:\n",
    "        min_l1 = model_gen.get_params()['alpha']\n",
    "        stack.push(min_l1)\n",
    "    # Getting the tail of our range.\n",
    "    elif min_l1 is not None and x is False:\n",
    "        popped_val = stack.pop()\n",
    "        max_l2 = popped_val\n",
    "        break\n",
    "    # If the last L1 parameter is equal to max_non_zero scenario\n",
    "    elif model_gen.get_params()['alpha'] == stopping_val and x:\n",
    "        max_l2 = model_gen.get_params()['alpha']\n",
    "        break\n",
    "    # No such tuning parameters in the list scenario.\n",
    "    elif model_gen.get_params()['alpha'] == stopping_val:\n",
    "        print('There is no L1 penalty value for this specific criteria.')\n",
    "        break\n",
    "    else:\n",
    "        stack.push(model_gen.get_params()['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 153)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_l1, max_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of penalties to find a solution with the lowest RSS\n",
    "\n",
    "Let's now explore region we found. We look for L1 penalty value in this range that minimizes the RSS on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_val = np.linspace(min_l1, max_l2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_valid = {}\n",
    "\n",
    "for l1_penalties in narrow_val:\n",
    "    model_narr = linear_model.Lasso(alpha=l1_penalties, normalize=True)\n",
    "    model_narr.fit(training[all_features], training['price'])\n",
    "    prediction = model_narr.predict(validation[all_features])\n",
    "    rss = sum((prediction - validation['price']) ** 2)\n",
    "    rss_valid[l1_penalties] = rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_opt = list(rss_valid.keys())[list(rss_valid.values()).index(min(rss_valid.values()))]\n",
    "l1_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Creating a model with 7 non-zero coefficients using L1 penalty with the lowest RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = linear_model.Lasso(alpha=l1_opt, normalize=True)\n",
    "model_final.fit(training[all_features], training['price'])\n",
    "final_non_zero = model_final.coef_[model_final.coef_ != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magnitude of non-zero coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.36540813e+04,   1.63165294e+02,  -2.69742928e+01,\n",
       "         5.20491250e+05,   4.23432580e+04,   1.17969590e+05,\n",
       "        -2.73352753e+03])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if number of non-zero coeff. is equal to max_non_zeros value.\n",
    "len(final_non_zero) is max_non_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some thoughts\n",
    "\n",
    "The model complexity decreases with shrinking number of coefficients but magnitude of non-zero weights has also impact on complexity. High magnitude of the coefficients tells us about a lot of emphasis used on that features and too small L1 penalty value used for training a model. It means that particular feature with large weight is a good predictor for the outcome and ends up overfitting to the training data. Considered range of L1 penalties values should be much wider. In that case RSS gets lower value due to error and magnitude of coefficients balance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
